{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tyrone Tracy Jr.', 'Jacob Cowing', \"Jha'Quan Jackson\", 'Ainias Smith', 'Xavier Legette', 'Malik Washington', 'Luke McCaffrey', 'Cornelius Johnson', 'Tahj Washington', 'Casey Washington', 'Jamari Thrash', 'Ricky Pearsall', 'Malachi Corley', 'Jalen McMillan', 'Rome Odunze', 'Devaughn Vele', \"Ja'lynn Polk\", 'Roman Wilson', 'Jermaine Burton', 'Brenden Rice', 'Johnny Wilson', 'Javon Baker', 'Tejhaun Palmer', 'Xavier Worthy', 'Anthony Gould', 'Troy Franklin', 'Marvin Harrison Jr.', 'Keon Coleman', 'Malik Nabers', 'Brian Thomas Jr.', 'Bub Means', 'Devontez Walker', 'Adonai Mitchell', 'Ladd McConkey']\n",
      "Training set size: 313\n",
      "Test set size: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qr/nj1x3v_n3g1c86l2ynq5dqkc0000gp/T/ipykernel_32925/1735297654.py:83: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_train = df_train.applymap(lambda x: float(x) if isinstance(x, (int, float, np.number)) or isinstance(x, decimal.Decimal) else x)\n",
      "/var/folders/qr/nj1x3v_n3g1c86l2ynq5dqkc0000gp/T/ipykernel_32925/1735297654.py:84: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_test = df_test.applymap(lambda x: float(x) if isinstance(x, (int, float, np.number)) or isinstance(x, decimal.Decimal) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    player_id                 name  predicted_fppg\n",
      "0       17387         Malik Nabers       12.708594\n",
      "1       17207  Marvin Harrison Jr.       12.205130\n",
      "2       17389     Brian Thomas Jr.       12.077241\n",
      "3       17487        Ladd McConkey       10.793444\n",
      "4       16322          Rome Odunze       10.258060\n",
      "5       17325         Keon Coleman        9.894829\n",
      "6       17085        Xavier Worthy        9.730159\n",
      "7       15855       Luke McCaffrey        9.151569\n",
      "8       16296       Malachi Corley        8.335012\n",
      "9       16390         Ja'lynn Polk        7.650890\n",
      "10      17486      Adonai Mitchell        6.779666\n",
      "11      16910          Javon Baker        6.335701\n",
      "12      15697       Xavier Legette        5.936728\n",
      "13      15553         Jacob Cowing        5.916331\n",
      "14      16757      Jermaine Burton        5.670541\n",
      "15      16899        Johnny Wilson        5.573112\n",
      "16      16232       Ricky Pearsall        5.186178\n",
      "17      17414            Bub Means        4.921267\n",
      "18      17429      Devontez Walker        4.852831\n",
      "19      16321       Jalen McMillan        4.747152\n",
      "20      15902    Cornelius Johnson        4.559361\n",
      "21      16609         Roman Wilson        4.196899\n",
      "22      17179        Troy Franklin        4.159166\n",
      "23      15606     Jha'Quan Jackson        4.071488\n",
      "24      15813     Malik Washington        3.609074\n",
      "25      17020       Tejhaun Palmer        3.430916\n",
      "26      15645         Ainias Smith        2.961910\n",
      "27      16020     Casey Washington        2.038403\n",
      "28      17160        Anthony Gould        1.945689\n",
      "29      15908      Tahj Washington        1.641650\n",
      "30      15156     Tyrone Tracy Jr.        1.611125\n",
      "31      16044        Jamari Thrash        1.607283\n",
      "32      16809         Brenden Rice        1.538353\n",
      "33      16359        Devaughn Vele        1.482073\n",
      "\n",
      "âœ… 41.18% of players were predicted within Â±3 FPPG of their actual.\n",
      "ðŸ“Š Expected vs. Actual FPPG:\n",
      " Actual FPPG  Predicted FPPG  Residuals (Actual - Predicted)\n",
      "       18.11       12.708594                        5.401406\n",
      "       16.47       12.077241                        4.392759\n",
      "       14.93       10.793444                        4.136556\n",
      "       11.68       12.205130                       -0.525130\n",
      "       11.01        9.730159                        1.279841\n",
      "       10.96        1.611125                        9.348875\n",
      "       10.42        4.747152                        5.672848\n",
      "        8.64       10.258060                       -1.618060\n",
      "        8.50        5.186178                        3.313822\n",
      "        8.42        9.894829                       -1.474829\n",
      "        8.19        1.482073                        6.707927\n",
      "        7.82        5.936728                        1.883272\n",
      "        4.19        4.159166                        0.030834\n",
      "        4.06        3.609074                        0.450926\n",
      "        3.83        4.921267                       -1.091267\n",
      "        3.22        6.779666                       -3.559666\n",
      "        2.53        2.961910                       -0.431910\n",
      "        2.18        7.650890                       -5.470890\n",
      "        2.05        9.151569                       -7.101569\n",
      "        1.05        5.670541                       -4.620541\n",
      "        1.01        4.852831                       -3.842831\n",
      "        0.93        5.573112                       -4.643112\n",
      "        0.85        5.916331                       -5.066331\n",
      "        0.80        8.335012                       -7.535012\n",
      "        0.58        1.607283                       -1.027283\n",
      "        0.41        1.945689                       -1.535689\n",
      "        0.30        2.038403                       -1.738403\n",
      "        0.20        6.335701                       -6.135701\n",
      "        0.11        4.071488                       -3.961488\n",
      "        0.00        3.430916                       -3.430916\n",
      "        0.00        4.559361                       -4.559361\n",
      "        0.00        1.538353                       -1.538353\n",
      "        0.00        1.641650                       -1.641650\n",
      "        0.00        4.196899                       -4.196899\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../')))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import decimal\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from util.db_util import DatabaseUtility\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# Read .bashrc and update os.environ\n",
    "bashrc_path = os.path.expanduser(\"~/.bashrc\")\n",
    "\n",
    "if os.path.exists(bashrc_path):\n",
    "    with open(bashrc_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"export \"):\n",
    "                key_value = line.replace(\"export \", \"\").strip().split(\"=\", 1)\n",
    "                if len(key_value) == 2:\n",
    "                    key, value = key_value\n",
    "                    os.environ[key] = value.strip().strip(\"'\").strip('\"')\n",
    "\n",
    "# Initialize database connection\n",
    "db_util = DatabaseUtility()\n",
    "\n",
    "# Execute query\n",
    "db_util.cursor.execute(\"\"\"\n",
    "    SELECT player_id, name, draft_cap, cupps_score, production_score, size_score, early_breakout, avg_fppg_nfl, total_fantasy_points_nfl FROM wr_model_data\n",
    "    WHERE draft_year NOT IN (2024, 2025)\n",
    "\"\"\")\n",
    "rows = db_util.cursor.fetchall()\n",
    "columns = [desc[0] for desc in db_util.cursor.description]\n",
    "df_train = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "# Fetch 2025 WR prospects\n",
    "db_util.cursor.execute(\"\"\"\n",
    "    SELECT player_id, name, draft_cap, cupps_score, production_score, size_score, early_breakout, avg_fppg_nfl, total_fantasy_points_nfl FROM wr_model_data\n",
    "    WHERE draft_year = 2024;\n",
    "\"\"\")\n",
    "rows_2025 = db_util.cursor.fetchall()\n",
    "df_test = pd.DataFrame(rows_2025, columns=columns)\n",
    "db_util.conn.close()\n",
    "\n",
    "print(list(name for name in df_test['name']))\n",
    "\n",
    "# Fill missing draft_cap\n",
    "\n",
    "df_test_identifiers = df_test[[\"player_id\", \"name\"]].copy()\n",
    "\n",
    "# Drop unneeded columns\n",
    "drop_cols = ['player_id', \n",
    "             'position', \n",
    "             'name', \n",
    "             'avg_pff_run_grade', \n",
    "             'peak_pff_run_grade', \n",
    "             'total_fantasy_points_nfl', \n",
    "             'peak_sos', \n",
    "             'peak_srs', \n",
    "             'ras', \n",
    "             'height', \n",
    "             'weight', \n",
    "             'peak_yac_per_rec', \n",
    "             'peak_tprr', \n",
    "             'avg_games_played',\n",
    "             'draft_year',\n",
    "             'avg_yac_per_rec',\n",
    "             'avg_sos'\n",
    "             ]\n",
    "\n",
    "df_train = df_train.drop(columns=[col for col in drop_cols if col in df_train.columns])\n",
    "df_test = df_test.drop(columns=[col for col in drop_cols if col in df_test.columns])\n",
    "\n",
    "if 'avg_fppg_nfl' in df_train.columns and 'total_fantasy_points_nfl' in df_train.columns:\n",
    "    df_train = df_train[~((df_train['avg_fppg_nfl'] == df_train['total_fantasy_points_nfl']) & (df_train['avg_fppg_nfl'] != 0))]\n",
    "\n",
    "df_train = df_train.applymap(lambda x: float(x) if isinstance(x, (int, float, np.number)) or isinstance(x, decimal.Decimal) else x)\n",
    "df_test = df_test.applymap(lambda x: float(x) if isinstance(x, (int, float, np.number)) or isinstance(x, decimal.Decimal) else x)\n",
    "\n",
    "df_train.fillna(df_train.mean(), inplace=True)\n",
    "df_test.fillna(df_test.mean(), inplace=True)\n",
    "\n",
    "print(f\"Training set size: {len(df_train)}\")\n",
    "print(f\"Test set size: {len(df_test)}\")\n",
    "\n",
    "y_train = df_train[\"avg_fppg_nfl\"]\n",
    "y_test_actual = df_test[\"avg_fppg_nfl\"]\n",
    "X_train = df_train.drop(columns=[\"avg_fppg_nfl\"])\n",
    "X_test = df_test.drop(columns=[\"avg_fppg_nfl\"])\n",
    "\n",
    "# Mean of CUPPS and production_score\n",
    "prod_weighted_cupps = (X_train[\"cupps_score\"] + X_train[\"production_score\"]) / 2\n",
    "\n",
    "# Weight boost for high combined_score (>= 80)\n",
    "sample_weights = np.log1p((X_train[\"cupps_score\"] + X_train[\"production_score\"]) / 2) * 2.5\n",
    "\n",
    "xgb_general = xgb.XGBRegressor(\n",
    "    max_depth=6, n_estimators=500, learning_rate=0.01,\n",
    "    subsample=0.8, colsample_bytree=0.7,\n",
    "    objective=\"reg:pseudohubererror\", random_state=42\n",
    ")\n",
    "xgb_general.fit(X_train, y_train)\n",
    "\n",
    "y_pred_general = xgb_general.predict(X_test)\n",
    "\n",
    "xgb_quantile = xgb.XGBRegressor(\n",
    "    max_depth=8, n_estimators=500, learning_rate=0.01,\n",
    "    subsample=0.8, colsample_bytree=0.7,\n",
    "    objective=\"reg:quantileerror\", quantile_alpha=0.99,\n",
    "    random_state=42\n",
    ")\n",
    "xgb_quantile.fit(X_train, y_train)\n",
    "\n",
    "y_pred_quantile = xgb_quantile.predict(X_test)\n",
    "\n",
    "meta_X = pd.DataFrame({\n",
    "    \"cupps_score\": X_test[\"cupps_score\"],\n",
    "    \"general_pred\": y_pred_general,\n",
    "    \"quantile_pred\": y_pred_quantile,\n",
    "}).fillna(0)\n",
    "\n",
    "meta_train_X = pd.DataFrame({\n",
    "    \"cupps_score\": X_train[\"cupps_score\"],\n",
    "    \"general_pred\": xgb_general.predict(X_train),\n",
    "    \"quantile_pred\": xgb_quantile.predict(X_train),\n",
    "}).fillna(0)\n",
    "\n",
    "meta_X[\"draft_cap\"] = X_test[\"draft_cap\"].fillna(300)\n",
    "meta_train_X[\"draft_cap\"] = X_train[\"draft_cap\"].fillna(300)\n",
    "\n",
    "meta_X[\"log_draft_cap\"] = np.log1p(meta_X[\"draft_cap\"])\n",
    "meta_train_X[\"log_draft_cap\"] = np.log1p(meta_train_X[\"draft_cap\"])\n",
    "\n",
    "# Add rank-based features\n",
    "meta_X[\"cupps_rank\"] = rankdata(X_test[\"cupps_score\"], method='min') / len(X_test)\n",
    "meta_train_X[\"cupps_rank\"] = rankdata(X_train[\"cupps_score\"], method='min') / len(X_train)\n",
    "\n",
    "meta_X[\"draft_rank\"] = rankdata(-X_test[\"draft_cap\"], method='min') / len(X_test)\n",
    "meta_train_X[\"draft_rank\"] = rankdata(-X_train[\"draft_cap\"], method='min') / len(X_train)\n",
    "\n",
    "meta_model = xgb.XGBRegressor(\n",
    "    max_depth=4, n_estimators=150, learning_rate=0.01,\n",
    "    subsample=0.9, colsample_bytree=0.9,\n",
    "    objective=\"reg:squarederror\", random_state=42\n",
    ")\n",
    "meta_model.fit(meta_train_X, y_train)\n",
    "\n",
    "meta_pred = meta_model.predict(meta_X)\n",
    "\n",
    "error_general = np.abs(meta_pred - y_pred_general)\n",
    "error_quantile = np.abs(meta_pred - y_pred_quantile)\n",
    "elite_bonus = np.clip((meta_pred - 10) / 10, 0, 0.5)\n",
    "\n",
    "blend_weight_quantile = np.clip(\n",
    "    (error_general / (error_general + error_quantile + 1e-8)) + elite_bonus,\n",
    "    0.05, 0.95\n",
    ")\n",
    "blend_weight_general = 1 - blend_weight_quantile\n",
    "\n",
    "y_pred_hybrid = (y_pred_quantile * blend_weight_quantile) + (y_pred_general * blend_weight_general)\n",
    "\n",
    "df_predictions = df_test_identifiers.copy()\n",
    "df_predictions[\"predicted_fppg\"] = y_pred_hybrid\n",
    "df_predictions = df_predictions.sort_values(by=\"predicted_fppg\", ascending=False).reset_index(drop=True)\n",
    "print(df_predictions)\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    \"Actual FPPG\": y_test_actual.values,\n",
    "    \"Predicted FPPG\": y_pred_hybrid,\n",
    "    \"Residuals (Actual - Predicted)\": y_test_actual.values - y_pred_hybrid\n",
    "})\n",
    "\n",
    "within_3 = df_results[\"Residuals (Actual - Predicted)\"].abs() <= 3\n",
    "percent_within_3 = within_3.mean() * 100\n",
    "print(f\"\\nâœ… {percent_within_3:.2f}% of players were predicted within Â±3 FPPG of their actual.\")\n",
    "\n",
    "print(\"ðŸ“Š Expected vs. Actual FPPG:\")\n",
    "print(df_results.sort_values(by=\"Actual FPPG\", ascending=False).to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
